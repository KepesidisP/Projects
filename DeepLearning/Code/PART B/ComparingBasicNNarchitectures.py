# -*- coding: utf-8 -*-
"""ComparingBasicNNArchitectures.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JOA6ON5jUvv-g9RhmDm5V9sciobCvGkW
"""

import keras
import numpy as np
import pandas as pd
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import random
import time

# the data, split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

#normalize data in range [0,1]
# a grayscale image has values in [0,255]
x_train = x_train/255
x_test = x_test/255

# plot 9 images as gray scale
plt.subplot(331)
plt.imshow(x_train[0], cmap=plt.get_cmap('gray'))
plt.subplot(332)
plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))
plt.subplot(333)
plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))
plt.subplot(334)
plt.imshow(x_train[3], cmap=plt.get_cmap('gray'))
plt.subplot(335)
plt.imshow(x_train[4], cmap=plt.get_cmap('gray'))
plt.subplot(336)
plt.imshow(x_train[5], cmap=plt.get_cmap('gray'))
plt.subplot(337)
plt.imshow(x_train[6], cmap=plt.get_cmap('gray'))
plt.subplot(338)
plt.imshow(x_train[7], cmap=plt.get_cmap('gray'))
plt.subplot(339)
plt.imshow(x_train[8], cmap=plt.get_cmap('gray'))
# show the plot
plt.show()
plt.pause(4)

#do some informative plotting
print('Input data (train) shape is:', x_train.shape)
print('Input data (test) shape is:', x_test.shape)

print('Output data (train) shape is:', y_train.shape)
print('Output data (test) shape is:', y_test.shape)

print('Train set has the following classes:', np.unique(y_train))
print('Test set has the following classes:', np.unique(y_test))

# do a one-hot-encoding for the outputs
y_train = keras.utils.to_categorical(y_train, 10)
y_test = keras.utils.to_categorical(y_test, 10)

#check the outputs' range (just to be sure)
print(np.max(x_train))
print(np.min(x_train))

def CNN_model():
  dropout_rate = 0.3

  # create a CNN structure
  my_cnn = Sequential()
  my_cnn.add(keras.Input(shape=(28,28,1)))
  my_cnn.add(Conv2D(6, kernel_size=(3,3), activation='relu'))
  my_cnn.add(MaxPooling2D(pool_size=(2,2)))
  my_cnn.add(Conv2D(12, kernel_size=(3,3), activation='relu'))
  my_cnn.add(MaxPooling2D(pool_size=(2,2)))
  my_cnn.add(Flatten())
  my_cnn.add(Dense(128, activation = 'relu'))
  my_cnn.add(Dropout(dropout_rate))
  my_cnn.add(Dense(128, activation = 'relu'))
  my_cnn.add(Dropout(dropout_rate))
  my_cnn.add(Dense(128, activation = 'relu'))
  my_cnn.add(Dropout(dropout_rate))
  my_cnn.add(Dense(10, activation = 'softmax'))

  #compile the model
  my_cnn.compile(loss=keras.losses.categorical_crossentropy, optimizer='Adam', metrics=['accuracy'])

  return my_cnn

def DNN_model():
  dropout_rate = 0.3

  # create a DNN structure
  my_dnn = Sequential()
  my_dnn.add(Flatten(input_shape=(28, 28, 1)))
  my_dnn.add(Dense(128, activation='relu'))
  my_dnn.add(Dropout(dropout_rate))
  my_dnn.add(Dense(128, activation='relu'))
  my_dnn.add(Dropout(dropout_rate))
  my_dnn.add(Dense(128, activation='relu'))
  my_dnn.add(Dropout(dropout_rate))
  my_dnn.add(Dense(128, activation='relu'))
  my_dnn.add(Dropout(dropout_rate))
  my_dnn.add(Dense(10, activation='softmax'))

  #compile the model
  my_dnn.compile(loss=keras.losses.categorical_crossentropy, optimizer='Adam', metrics=['accuracy'])

  return my_dnn

kF = KFold(n_splits=6, shuffle=True)

results = []
i=1
start = time.time()
best_dnn=0
best_cnn=0
for train_index, val_index in kF.split(x_train): #Generate indices to split data.

    x_train_fold, x_val_fold = x_train[train_index], x_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    CNN = CNN_model()
    DNN = DNN_model()

    #DNN model-------------------------------------------------------------------------------------
    DNNhistory = DNN.fit(x_train_fold, y_train_fold, batch_size=125, epochs=10, validation_data=(x_val_fold,y_val_fold) )
    # Evaluate DNN model on validation set
    dnn_loss, dnn_accuracy = DNN.evaluate(x_val_fold, y_val_fold)

    #Train
    # Use the trained model to make predictions
    y_val_pred = DNN.predict(x_val_fold)
    #convert DNN outputs to categorical, i.e. 0, 1, 2, ..., numofClasses
    dnn_y_val_fold = np.argmax(y_val_fold, axis=1)
    dnn_y_val_pred = np.argmax(y_val_pred, axis=1)

    # Calculate performance metrics for valuation
    accuracy = accuracy_score(dnn_y_val_fold, dnn_y_val_pred)
    precision = precision_score(dnn_y_val_fold, dnn_y_val_pred, average='macro')
    recall = recall_score(dnn_y_val_fold, dnn_y_val_pred, average='macro')
    f1 = f1_score(dnn_y_val_fold, dnn_y_val_pred, average='macro')
    # Append results to the list
    results.append(['DNN', 'Train', i, accuracy, precision, recall, f1])

    #Test
    # Use the trained model to make predictions
    y_test_pred = DNN.predict(x_test)
    dnn_y_test_pred = np.argmax(y_test_pred, axis=1)
    dnn_y_test= np.argmax(y_test, axis=1)

    # Calculate performance metrics for test
    accuracy = accuracy_score(dnn_y_test, dnn_y_test_pred)
    precision = precision_score(dnn_y_test, dnn_y_test_pred, average='macro')
    recall = recall_score(dnn_y_test, dnn_y_test_pred, average='macro')
    f1 = f1_score(dnn_y_test, dnn_y_test_pred, average='macro')
    # Append results to the list
    results.append(['DNN', 'Test', i, accuracy, precision, recall, f1])
    if accuracy > best_dnn:
      #saving the best *trained* model as an h5 file
      print("DNN ACC:",accuracy)
      DNN.save('dnn.h5')
      #plot and save the DNNhistory performance scores
      plt.figure(figsize=(14,6))
      plt.plot(DNNhistory.history[list(DNNhistory.history.keys())[0]])
      plt.plot(DNNhistory.history[list(DNNhistory.history.keys())[2]])
      plt.title('Cross entropy')
      plt.ylabel(list(DNNhistory.history.keys())[0])
      plt.xlabel('epoch')
      plt.legend(['train', 'val'], loc='upper left')
      plt.savefig('DNNgraph.jpg', format='jpeg')
      plt.show()
      best_dnn=accuracy

    #CNN model-------------------------------------------------------------------------------------
    CNNhistory = CNN.fit(x_train_fold, y_train_fold, batch_size=125, epochs=10, validation_data=(x_val_fold,y_val_fold))
    # Evaluate CNN model on validation set
    cnn_loss, cnn_accuracy = CNN.evaluate(x_val_fold, y_val_fold)

    #Train
    # Use the trained model to make predictions
    y_val_pred = CNN.predict(x_val_fold)
    #convert CNN outputs to categorical, i.e. 0, 1, 2, ..., numofClasses
    cnn_y_val_fold = np.argmax(y_val_fold, axis=1)
    cnn_y_val_pred = np.argmax(y_val_pred, axis=1)

    # Calculate performance metrics for valuation
    accuracy = accuracy_score(cnn_y_val_fold, cnn_y_val_pred)
    precision = precision_score(cnn_y_val_fold, cnn_y_val_pred, average='macro')
    recall = recall_score(cnn_y_val_fold, cnn_y_val_pred, average='macro')
    f1 = f1_score(cnn_y_val_fold, cnn_y_val_pred, average='macro')
    # Append results to the list
    results.append(['CNN', 'Train', i, accuracy, precision, recall, f1])

    #Test
    # Use the trained model to make predictions
    y_test_pred = CNN.predict(x_test)
    #cnn_y_test_pred = y_test_pred
    cnn_y_test_pred = np.argmax(y_test_pred, axis=1)
    cnn_y_test= np.argmax(y_test, axis=1)

    # Calculate performance metrics for test
    accuracy = accuracy_score(cnn_y_test, cnn_y_test_pred)
    precision = precision_score(cnn_y_test, cnn_y_test_pred, average='macro')
    recall = recall_score(cnn_y_test, cnn_y_test_pred, average='macro')
    f1 = f1_score(cnn_y_test, cnn_y_test_pred, average='macro')
    # Append results to the list
    results.append(['CNN', 'Test', i, accuracy, precision, recall, f1])
    if accuracy > best_cnn:
      #saving the best *trained* model as an h5 file
      print("CNN ACC:",accuracy)
      CNN.save('cnn.h5')
      #plot and save the CNNhistory performance scores
      plt.figure(figsize=(14,6))
      plt.plot(CNNhistory.history[list(CNNhistory.history.keys())[0]])
      plt.plot(CNNhistory.history[list(CNNhistory.history.keys())[2]])
      plt.title('Cross entropy')
      plt.ylabel(list(CNNhistory.history.keys())[0])
      plt.xlabel('epoch')
      plt.legend(['train', 'val'], loc='upper left')
      plt.savefig('CNNgraph.jpg', format='jpeg')
      plt.show()
      best_cnn=accuracy

    i=i+1

end = time.time()
print("The time of execution of above program is :",(end-start)/60, "m")

df_results = pd.DataFrame(results, columns=['Model', 'Dataset', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1-Score'])
df_results

df_results.to_csv('erotima1.csv', index=False)

from tensorflow.keras.utils import plot_model

plot_model(DNN, to_file='dnn_architecture.png', show_shapes=True, show_layer_names=True)

plot_model(CNN, to_file='cnn_architecture.png', show_shapes=True, show_layer_names=True)